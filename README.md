# ConstructionRAG - DeepWiki for Construction Sites

An AI-powered construction document processing and Q&A system that automatically processes construction documents and enables intelligent Q&A about every aspect of construction projects. Think of it as a **DeepWiki for Construction Sites** - just like DeepWiki analyzes code repositories, we analyze construction documentation to create comprehensive project knowledge bases.

## ğŸ—ï¸ What is ConstructionRAG?

ConstructionRAG is a production-ready RAG (Retrieval-Augmented Generation) system specifically designed for construction projects. It:

1. **Processes Construction Documents**: Automatically extracts text, tables, and images from PDFs (plans, specifications, permits)
2. **Generates Intelligent Responses**: Answers complex questions about project requirements, timelines, and specifications
3. **Organizes by Building Systems**: Structures information by electrical, plumbing, HVAC, and structural systems
4. **Supports Danish Language**: Optimized for Danish construction documents with multilingual AI models

### Key Features
- **Complete Document Pipeline**: Partition â†’ Metadata â†’ Enrichment â†’ Chunking â†’ Embedding
- **Advanced Query Processing**: Semantic variations, HyDE queries, and vector similarity search
- **Dual Upload System**: Anonymous email uploads + authenticated user projects
- **Production Deployment**: Live on Railway (backend) and Streamlit Cloud (frontend)
- **Construction-Specific**: Optimized for technical construction content and Danish language

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Docker and Docker Compose
- API keys for:
  - Voyage AI (embeddings - voyage-multilingual-2)
  - OpenRouter (query processing and generation)
  - Anthropic (VLM captioning)
  - Supabase (database and authentication)

### Local Development

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ConstructionRAG
   ```

2. **Set up environment variables**
   ```bash
   # Backend
   cp backend/env.example backend/.env
   # Edit backend/.env with your API keys and Supabase credentials
   
   # Frontend
   cp frontend/env.example frontend/.env
   # Edit frontend/.env with your backend URL and Supabase credentials
   ```

3. **Start the application**
   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - Health Check: http://localhost:8000/health

### Production Deployment

#### Backend (Railway)
1. Connect your GitHub repository to Railway
2. Railway will automatically detect the `backend/Dockerfile`
3. Add environment variables in Railway dashboard
4. Deploy - Live at: https://constructionrag-production.up.railway.app/

#### Frontend (Railway)
1. Connect your GitHub repository to Railway
2. Railway will automatically detect the `frontend/Dockerfile`
3. Add environment variables in Railway dashboard
4. Deploy

## ğŸ“ Project Structure

```
ConstructionRAG/
â”œâ”€â”€ backend/                    # FastAPI Application (Railway)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI application entry point
â”‚   â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”‚   â”œâ”€â”€ api/               # API endpoints (auth, documents, queries, pipeline)
â”‚   â”‚   â”œâ”€â”€ pipeline/          # RAG pipeline steps
â”‚   â”‚   â”‚   â”œâ”€â”€ indexing/      # Document processing pipeline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ steps/     # Partition, Metadata, Enrichment, Chunking, Embedding
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ config/    # Pipeline configuration
â”‚   â”‚   â”‚   â””â”€â”€ querying/      # Query processing pipeline
â”‚   â”‚   â”‚       â”œâ”€â”€ steps/     # Query Processing, Retrieval, Generation
â”‚   â”‚   â”‚       â””â”€â”€ config/    # Query configuration
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”œâ”€â”€ models/            # Data models
â”‚   â”‚   â””â”€â”€ utils/             # Utilities
â”‚   â”œâ”€â”€ tests/                 # Integration and unit tests
â”‚   â”œâ”€â”€ Dockerfile             # Backend Docker configuration
â”‚   â””â”€â”€ requirements.txt       # Backend dependencies
â”œâ”€â”€ frontend/                  # Next.js Application (Railway)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/               # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx     # Root layout
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx       # Home page
â”‚   â”‚   â”‚   â”œâ”€â”€ projects/      # Public projects (anonymous access)
â”‚   â”‚   â”‚   â””â”€â”€ (app)/         # Authenticated app routes
â”‚   â”‚   â”‚       â””â”€â”€ dashboard/ # Private projects and user management
â”‚   â”‚   â”œâ”€â”€ components/        # Reusable UI components
â”‚   â”‚   â””â”€â”€ lib/               # Utilities and helpers
â”‚   â”œâ”€â”€ package.json           # Node.js dependencies
â”‚   â””â”€â”€ Dockerfile             # Frontend Docker configuration
â”œâ”€â”€ own/                       # Project documentation and learning
â”‚   â”œâ”€â”€ ARCHITECTURE_OVERVIEW.md
â”‚   â”œâ”€â”€ PIPELINE_CONFIGURATION.md
â”‚   â”œâ”€â”€ DATABASE_DESIGN.md
â”‚   â””â”€â”€ SYSTEM_INTEGRATION.md
â”œâ”€â”€ config/                    # Configuration files
â”œâ”€â”€ supabase/                  # Database migrations and schema
â”œâ”€â”€ notebooks/                 # Development notebooks and experiments
â””â”€â”€ docker-compose.yml         # Local development
```

## ğŸ”§ Configuration

### Pipeline Configuration
The system uses JSON configuration files for pipeline parameters:

- `backend/src/config/pipeline/pipeline_config.json` - Unified pipeline configuration

### Configuration Features
- **Hot Reloading**: Changes take effect immediately for new jobs
- **Environment Variables**: Support for variable substitution
- **Validation**: Automatic validation of configuration parameters
- **Optimization Guides**: Pre-configured settings for different use cases

### Environment Variables

#### Backend (.env)
```bash
# Database
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# AI/ML APIs
VOYAGE_API_KEY=your_voyage_api_key
OPENROUTER_API_KEY=your_openrouter_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# Application
ENVIRONMENT=development
LOG_LEVEL=DEBUG
```

#### Frontend (.env)
```bash
# Backend connection
NEXT_PUBLIC_API_URL=http://localhost:8000

# Authentication
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

# Application
ENVIRONMENT=development
```

## ğŸ§ª Testing

### Local Testing
```bash
# Backend tests (from project root)
cd backend
pytest tests/

# Integration tests
pytest tests/integration/

# Frontend tests
cd frontend
npm run dev
```

### End-to-End Testing
```bash
# Start the full stack
docker-compose up --build

# Run integration tests
pytest backend/tests/integration/
```

## ğŸ“Š Monitoring & Observability

- **Supabase**: Database metrics, logs, and Row Level Security
- **Railway**: Application metrics, logs, and health checks
- **Railway Frontend**: Frontend metrics and logs
- **Structured Logging**: Comprehensive logging with correlation IDs
- **Health Checks**: `/health` endpoint for monitoring

## ğŸš€ Deployment

### Railway (Backend)
- Automatic deployment from GitHub
- Docker-based deployment
- Environment variable management
- Health checks and monitoring

### Railway (Frontend)
- Automatic deployment from GitHub
- Docker-based deployment
- Environment variable management
- Custom domain support